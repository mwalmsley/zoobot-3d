{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "# local libs\n",
    "import utils\n",
    "import engine\n",
    "import mask_rcnn_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNN\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.models.detection.backbone_utils import LastLevelMaxPool\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH_DEVICE = 'mps' # there is currently a bug: https://github.com/pytorch/pytorch/issues/78915\n",
    "TORCH_DEVICE = 'cpu'\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     TORCH_DEVICE = 'cuda'\n",
    "#     GPU_COUNT = torch.cuda.device_count()\n",
    "#     print('Device: {}, Number of GPUs: {}'.format(TORCH_DEVICE, GPU_COUNT))\n",
    "# else:\n",
    "#     TORCH_DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - Output directory for logs and checkpoints exists.\n",
      "OK - Pre-trained model checkpoint exists.\n",
      "OK - Parquet-file with training data exists.\n",
      "OK - Directory with image data exists.\n"
     ]
    }
   ],
   "source": [
    "with open('Zoobot-backbone-transfer_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# some checks, create directories if necessary\n",
    "# model logs\n",
    "if os.path.exists(config['log_dir']):\n",
    "    try:\n",
    "        os.makedirs(config['log_dir'] + 'logs_eval/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(config['log_dir'] + 'logs_train/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    print('OK - Output directory for logs and checkpoints exists.')\n",
    "else:\n",
    "    print('WARNING - Output directory for logs and checkpoints DOES NOT exist.')\n",
    "    os.mkdir(config['log_dir'])\n",
    "    os.mkdir(config['log_dir'] + 'logs_eval/')\n",
    "    os.mkdir(config['log_dir'] + 'logs_train/')\n",
    "\n",
    "    try:\n",
    "        os.makedirs(config['log_dir'] + 'logs_eval/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        os.makedirs(config['log_dir'] + 'logs_train/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    print('OK - Output directory for logs and checkpoints created.')\n",
    "\n",
    "# Pre-trained model checkpoint\n",
    "if os.path.exists(config['pretrained_ckpt']):\n",
    "    print('OK - Pre-trained model checkpoint exists.')\n",
    "else:\n",
    "    print('ERROR - Pre-trained model checkpoint is MISSING.')\n",
    "\n",
    "# Table with training data\n",
    "if os.path.exists(config['data_table']):\n",
    "    print('OK - Parquet-file with training data exists.')\n",
    "else:\n",
    "    print('ERROR - Parquet-file with training data is MISSING.')\n",
    "\n",
    "# Directory with image data\n",
    "if os.path.exists(config['image_dir']):\n",
    "    print('OK - Directory with image data exists.')\n",
    "else:\n",
    "    print('ERROR - Directory with image data is MISSING.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_dict(train_df, val_df, image_dir, batch_size):\n",
    "    image_datasets = {}\n",
    "\n",
    "    image_datasets['train'] = mask_rcnn_dataset.MaskGalaxyDataset(\n",
    "        dataframe=train_df,\n",
    "        image_dir=image_dir,\n",
    "        transforms=get_transform(train=True)\n",
    "    )\n",
    "    image_datasets['val'] = mask_rcnn_dataset.MaskGalaxyDataset(\n",
    "        dataframe=val_df,\n",
    "        image_dir=image_dir,\n",
    "        transforms=get_transform(train=False)\n",
    "    )\n",
    "    \n",
    "    return {x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "        collate_fn=utils.collate_fn\n",
    "    ) for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask R-CNN with 3 channels\n",
    "class Resnet50WithFPN(torch.nn.Module):\n",
    "    def __init__(self, ckpt):\n",
    "        super(Resnet50WithFPN, self).__init__()\n",
    "\n",
    "        # m = torchvision.models.resnet50()\n",
    "        self.ckpt = ckpt\n",
    "        m = torchvision.models.resnet50(num_classes=281)\n",
    "        checkpoint = torch.load(self.ckpt, map_location=torch.device(TORCH_DEVICE))\n",
    "        checkpoint = {\n",
    "            key.replace('encoder.', ''): value for key, value in checkpoint['state_dict'].items()\n",
    "        }\n",
    "        checkpoint = {\n",
    "            key.replace('head.1.0.', 'fc.'): value for key, value in checkpoint.items()\n",
    "        }\n",
    "        m.load_state_dict(checkpoint)\n",
    "\n",
    "        # Extract 4 main layers (note: FRCNN needs this particular name mapping for return nodes)\n",
    "        self.body = create_feature_extractor(\n",
    "            m,\n",
    "            return_nodes={f'layer{k}': str(v) for v, k in enumerate([1, 2, 3, 4])}\n",
    "        )\n",
    "        \n",
    "        # Dry run to get number of channels for FPN\n",
    "        inp = torch.randn(2, 3, 224, 224)\n",
    "        # inp = inp.to(TORCH_DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = self.body(inp)\n",
    "        in_channels_list = [o.shape[1] for o in out.values()]\n",
    "        \n",
    "        # Build FPN\n",
    "        self.out_channels = 256\n",
    "        self.fpn = FeaturePyramidNetwork(\n",
    "            in_channels_list, out_channels=self.out_channels,\n",
    "            extra_blocks=LastLevelMaxPool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.body(x)\n",
    "        x = self.fpn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "        ckpt, \n",
    "        num_classes=3, \n",
    "        trainable_layers=0, \n",
    "        image_mean=[0.485, 0.456, 0.406],\n",
    "        image_std=[0.229, 0.224, 0.225]\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Creates the model object for Faster R-CNN\n",
    "\n",
    "    Args:\n",
    "      ckpt (str): path to checkpoint for the Zoobot backbone\n",
    "      num_classes (int): number of classes the detector should output, \n",
    "        must include a class for the background\n",
    "      trainable_layers (int): number of blocks of the classification backbone,\n",
    "        counted from top, that should be made trainable\n",
    "        e.g. 0 - all blocks fixed, 5 - all blocks and incl. 'backbone.body.conv1' trainable\n",
    "\n",
    "    Returns:\n",
    "      Mask R-CNN model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the model\n",
    "    model = MaskRCNN(Resnet50WithFPN(ckpt=ckpt), num_classes=num_classes)\n",
    "\n",
    "    # change the Transform layer to fit for custom mean and stddev of image values\n",
    "    grcnn = GeneralizedRCNNTransform(\n",
    "        min_size=800, \n",
    "        max_size=1333, \n",
    "        image_mean=image_mean, \n",
    "        image_std=image_std\n",
    "    )\n",
    "    model.transform = grcnn\n",
    "\n",
    "    # make sure, backbone layers are freezed after creating the model\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if name.startswith('backbone.body.'):\n",
    "            parameter.requires_grad = False\n",
    "    \n",
    "    # unfreeze selected layers\n",
    "    if trainable_layers < 0 or trainable_layers > 5:\n",
    "        raise ValueError(f\"Trainable layers should be in the range [0, 5], got {trainable_layers}\")\n",
    "    \n",
    "    layers_to_train = [\n",
    "        'backbone.body.layer4', \n",
    "        'backbone.body.layer3', \n",
    "        'backbone.body.layer2', \n",
    "        'backbone.body.layer1', \n",
    "        'backbone.body.conv1'\n",
    "    ][:trainable_layers]\n",
    "    \n",
    "    if trainable_layers == 5:\n",
    "        layers_to_train.append('backbone.body.bn1')\n",
    "\n",
    "    for layer in layers_to_train:\n",
    "        for name, parameter in model.named_parameters():\n",
    "            if name.startswith(layer):\n",
    "                parameter.requires_grad_(True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Galaxy catalogue\n",
    "df = pd.read_parquet(config['data_table'], engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/245]  eta: 0:57:06  lr: 0.000001  loss: 5.8063 (5.8063)  loss_classifier: 1.1606 (1.1606)  loss_box_reg: 0.0134 (0.0134)  loss_mask: 3.9387 (3.9387)  loss_objectness: 0.6850 (0.6850)  loss_rpn_box_reg: 0.0086 (0.0086)  time: 13.9860  data: 0.0467\n",
      "Epoch: [0]  [ 10/245]  eta: 0:49:16  lr: 0.000005  loss: 5.4770 (5.2499)  loss_classifier: 1.0153 (0.9660)  loss_box_reg: 0.0092 (0.0085)  loss_mask: 3.8018 (3.5862)  loss_objectness: 0.6812 (0.6801)  loss_rpn_box_reg: 0.0086 (0.0090)  time: 12.5800  data: 0.0557\n",
      "Epoch: [0]  [ 20/245]  eta: 0:43:51  lr: 0.000009  loss: 3.6999 (4.3101)  loss_classifier: 0.5545 (0.6773)  loss_box_reg: 0.0097 (0.0109)  loss_mask: 2.5409 (2.9423)  loss_objectness: 0.6701 (0.6681)  loss_rpn_box_reg: 0.0097 (0.0115)  time: 11.5830  data: 0.0509\n",
      "Epoch: [0]  [ 30/245]  eta: 0:40:36  lr: 0.000013  loss: 2.5536 (3.6099)  loss_classifier: 0.2433 (0.5192)  loss_box_reg: 0.0189 (0.0173)  loss_mask: 1.7367 (2.4104)  loss_objectness: 0.6311 (0.6489)  loss_rpn_box_reg: 0.0096 (0.0140)  time: 10.6466  data: 0.0461\n",
      "Epoch: [0]  [ 40/245]  eta: 0:38:03  lr: 0.000017  loss: 1.8966 (3.1689)  loss_classifier: 0.1801 (0.4387)  loss_box_reg: 0.0502 (0.0285)  loss_mask: 1.0438 (2.0662)  loss_objectness: 0.5720 (0.6227)  loss_rpn_box_reg: 0.0075 (0.0128)  time: 10.5565  data: 0.0470\n",
      "Epoch: [0]  [ 50/245]  eta: 0:35:46  lr: 0.000021  loss: 1.6771 (2.8565)  loss_classifier: 0.1388 (0.3754)  loss_box_reg: 0.0552 (0.0316)  loss_mask: 0.9509 (1.8458)  loss_objectness: 0.4990 (0.5911)  loss_rpn_box_reg: 0.0077 (0.0126)  time: 10.5033  data: 0.0465\n",
      "Epoch: [0]  [ 60/245]  eta: 0:33:45  lr: 0.000025  loss: 1.4651 (2.6165)  loss_classifier: 0.1113 (0.3323)  loss_box_reg: 0.0521 (0.0355)  loss_mask: 0.8789 (1.6818)  loss_objectness: 0.4061 (0.5549)  loss_rpn_box_reg: 0.0084 (0.0121)  time: 10.5552  data: 0.0459\n",
      "Epoch: [0]  [ 70/245]  eta: 0:31:55  lr: 0.000029  loss: 1.2875 (2.4229)  loss_classifier: 0.1100 (0.3017)  loss_box_reg: 0.0605 (0.0398)  loss_mask: 0.7713 (1.5529)  loss_objectness: 0.3234 (0.5166)  loss_rpn_box_reg: 0.0083 (0.0119)  time: 10.7833  data: 0.0450\n",
      "Epoch: [0]  [ 80/245]  eta: 0:30:18  lr: 0.000033  loss: 1.1810 (2.2690)  loss_classifier: 0.1123 (0.2794)  loss_box_reg: 0.0697 (0.0453)  loss_mask: 0.7341 (1.4544)  loss_objectness: 0.2346 (0.4783)  loss_rpn_box_reg: 0.0087 (0.0116)  time: 11.2459  data: 0.0451\n",
      "Epoch: [0]  [ 90/245]  eta: 0:28:26  lr: 0.000037  loss: 1.1030 (2.1345)  loss_classifier: 0.1064 (0.2602)  loss_box_reg: 0.0820 (0.0491)  loss_mask: 0.6904 (1.3693)  loss_objectness: 0.1836 (0.4435)  loss_rpn_box_reg: 0.0087 (0.0124)  time: 11.2309  data: 0.0455\n",
      "Epoch: [0]  [100/245]  eta: 0:26:38  lr: 0.000041  loss: 1.0267 (2.0240)  loss_classifier: 0.1064 (0.2458)  loss_box_reg: 0.0886 (0.0547)  loss_mask: 0.6602 (1.3010)  loss_objectness: 0.1197 (0.4106)  loss_rpn_box_reg: 0.0076 (0.0120)  time: 11.0182  data: 0.0459\n",
      "Epoch: [0]  [110/245]  eta: 0:24:45  lr: 0.000046  loss: 0.9687 (1.9269)  loss_classifier: 0.0989 (0.2319)  loss_box_reg: 0.0998 (0.0587)  loss_mask: 0.6575 (1.2429)  loss_objectness: 0.1014 (0.3818)  loss_rpn_box_reg: 0.0075 (0.0116)  time: 11.0061  data: 0.0450\n",
      "Epoch: [0]  [120/245]  eta: 0:22:54  lr: 0.000050  loss: 0.9115 (1.8427)  loss_classifier: 0.0865 (0.2199)  loss_box_reg: 0.0998 (0.0622)  loss_mask: 0.6498 (1.1928)  loss_objectness: 0.0773 (0.3565)  loss_rpn_box_reg: 0.0058 (0.0113)  time: 10.8676  data: 0.0482\n",
      "Epoch: [0]  [130/245]  eta: 0:21:07  lr: 0.000054  loss: 0.8820 (1.7700)  loss_classifier: 0.0863 (0.2098)  loss_box_reg: 0.1047 (0.0665)  loss_mask: 0.6189 (1.1479)  loss_objectness: 0.0727 (0.3349)  loss_rpn_box_reg: 0.0058 (0.0110)  time: 11.0823  data: 0.0512\n",
      "Epoch: [0]  [140/245]  eta: 0:19:18  lr: 0.000058  loss: 0.8744 (1.7066)  loss_classifier: 0.0831 (0.2005)  loss_box_reg: 0.1131 (0.0697)  loss_mask: 0.6187 (1.1100)  loss_objectness: 0.0665 (0.3157)  loss_rpn_box_reg: 0.0071 (0.0108)  time: 11.2618  data: 0.0481\n",
      "Epoch: [0]  [150/245]  eta: 0:17:29  lr: 0.000062  loss: 0.8405 (1.6484)  loss_classifier: 0.0749 (0.1924)  loss_box_reg: 0.1018 (0.0720)  loss_mask: 0.6047 (1.0744)  loss_objectness: 0.0613 (0.2990)  loss_rpn_box_reg: 0.0074 (0.0107)  time: 11.2072  data: 0.0470\n",
      "Epoch: [0]  [160/245]  eta: 0:15:38  lr: 0.000066  loss: 0.8326 (1.5989)  loss_classifier: 0.0744 (0.1856)  loss_box_reg: 0.1064 (0.0746)  loss_mask: 0.5671 (1.0438)  loss_objectness: 0.0602 (0.2843)  loss_rpn_box_reg: 0.0090 (0.0107)  time: 11.0698  data: 0.0468\n",
      "Epoch: [0]  [170/245]  eta: 0:13:49  lr: 0.000070  loss: 0.8218 (1.5530)  loss_classifier: 0.0720 (0.1791)  loss_box_reg: 0.1093 (0.0764)  loss_mask: 0.5633 (1.0155)  loss_objectness: 0.0597 (0.2714)  loss_rpn_box_reg: 0.0098 (0.0106)  time: 11.1304  data: 0.0505\n",
      "Epoch: [0]  [180/245]  eta: 0:11:58  lr: 0.000074  loss: 0.8127 (1.5173)  loss_classifier: 0.0672 (0.1727)  loss_box_reg: 0.0978 (0.0774)  loss_mask: 0.5479 (0.9897)  loss_objectness: 0.0542 (0.2643)  loss_rpn_box_reg: 0.0098 (0.0133)  time: 11.2392  data: 0.0511\n",
      "Epoch: [0]  [190/245]  eta: 0:10:08  lr: 0.000078  loss: 0.7933 (1.4808)  loss_classifier: 0.0667 (0.1675)  loss_box_reg: 0.0996 (0.0790)  loss_mask: 0.5443 (0.9680)  loss_objectness: 0.0501 (0.2532)  loss_rpn_box_reg: 0.0088 (0.0131)  time: 11.1582  data: 0.0471\n",
      "Epoch: [0]  [200/245]  eta: 0:08:19  lr: 0.000082  loss: 0.7871 (1.4452)  loss_classifier: 0.0698 (0.1628)  loss_box_reg: 0.1027 (0.0803)  loss_mask: 0.5385 (0.9458)  loss_objectness: 0.0469 (0.2433)  loss_rpn_box_reg: 0.0072 (0.0129)  time: 11.4573  data: 0.0484\n",
      "Epoch: [0]  [210/245]  eta: 0:06:28  lr: 0.000086  loss: 0.7540 (1.4121)  loss_classifier: 0.0687 (0.1584)  loss_box_reg: 0.0957 (0.0811)  loss_mask: 0.5382 (0.9264)  loss_objectness: 0.0410 (0.2336)  loss_rpn_box_reg: 0.0064 (0.0126)  time: 11.4879  data: 0.0487\n",
      "Epoch: [0]  [220/245]  eta: 0:04:38  lr: 0.000091  loss: 0.7326 (1.3818)  loss_classifier: 0.0626 (0.1542)  loss_box_reg: 0.0883 (0.0815)  loss_mask: 0.5261 (0.9087)  loss_objectness: 0.0351 (0.2249)  loss_rpn_box_reg: 0.0056 (0.0125)  time: 11.3539  data: 0.0492\n",
      "Epoch: [0]  [230/245]  eta: 0:02:47  lr: 0.000095  loss: 0.7387 (1.3553)  loss_classifier: 0.0638 (0.1506)  loss_box_reg: 0.0924 (0.0824)  loss_mask: 0.5312 (0.8924)  loss_objectness: 0.0354 (0.2173)  loss_rpn_box_reg: 0.0091 (0.0125)  time: 11.5308  data: 0.0494\n",
      "Epoch: [0]  [240/245]  eta: 0:00:55  lr: 0.000099  loss: 0.7217 (1.3304)  loss_classifier: 0.0686 (0.1475)  loss_box_reg: 0.1050 (0.0833)  loss_mask: 0.5312 (0.8776)  loss_objectness: 0.0328 (0.2096)  loss_rpn_box_reg: 0.0090 (0.0124)  time: 11.7336  data: 0.0467\n",
      "Epoch: [0]  [244/245]  eta: 0:00:11  lr: 0.000100  loss: 0.7159 (1.3216)  loss_classifier: 0.0686 (0.1464)  loss_box_reg: 0.1047 (0.0835)  loss_mask: 0.5450 (0.8727)  loss_objectness: 0.0295 (0.2067)  loss_rpn_box_reg: 0.0067 (0.0123)  time: 11.9181  data: 0.0461\n",
      "Epoch: [0] Total time: 0:45:43 (11.1959 s / it)\n",
      "Epoch: [1]  [  0/245]  eta: 0:53:08  lr: 0.000100  loss: 1.2356 (1.2356)  loss_classifier: 0.0683 (0.0683)  loss_box_reg: 0.0845 (0.0845)  loss_mask: 0.5945 (0.5945)  loss_objectness: 0.2700 (0.2700)  loss_rpn_box_reg: 0.2183 (0.2183)  time: 13.0138  data: 0.0456\n",
      "Epoch: [1]  [ 10/245]  eta: 0:51:12  lr: 0.000100  loss: 0.7668 (0.8075)  loss_classifier: 0.0878 (0.0830)  loss_box_reg: 0.1213 (0.1171)  loss_mask: 0.5293 (0.5236)  loss_objectness: 0.0306 (0.0538)  loss_rpn_box_reg: 0.0081 (0.0300)  time: 13.0758  data: 0.0485\n",
      "Epoch: [1]  [ 20/245]  eta: 0:48:44  lr: 0.000100  loss: 0.7471 (0.7663)  loss_classifier: 0.0696 (0.0747)  loss_box_reg: 0.1141 (0.1129)  loss_mask: 0.5006 (0.5188)  loss_objectness: 0.0265 (0.0406)  loss_rpn_box_reg: 0.0068 (0.0194)  time: 12.9968  data: 0.0471\n",
      "Epoch: [1]  [ 30/245]  eta: 0:44:59  lr: 0.000100  loss: 0.6829 (0.7347)  loss_classifier: 0.0635 (0.0715)  loss_box_reg: 0.1007 (0.1070)  loss_mask: 0.4971 (0.5075)  loss_objectness: 0.0209 (0.0336)  loss_rpn_box_reg: 0.0065 (0.0151)  time: 12.2731  data: 0.0452\n",
      "Epoch: [1]  [ 40/245]  eta: 0:42:38  lr: 0.000100  loss: 0.6660 (0.7236)  loss_classifier: 0.0658 (0.0719)  loss_box_reg: 0.0905 (0.1050)  loss_mask: 0.4830 (0.5028)  loss_objectness: 0.0192 (0.0304)  loss_rpn_box_reg: 0.0068 (0.0136)  time: 11.9361  data: 0.0473\n",
      "Epoch: [1]  [ 50/245]  eta: 0:40:24  lr: 0.000100  loss: 0.6812 (0.7201)  loss_classifier: 0.0650 (0.0703)  loss_box_reg: 0.0925 (0.1024)  loss_mask: 0.4838 (0.5063)  loss_objectness: 0.0195 (0.0285)  loss_rpn_box_reg: 0.0080 (0.0126)  time: 12.2433  data: 0.0481\n",
      "Epoch: [1]  [ 60/245]  eta: 0:38:09  lr: 0.000100  loss: 0.6931 (0.7238)  loss_classifier: 0.0645 (0.0714)  loss_box_reg: 0.1003 (0.1045)  loss_mask: 0.5141 (0.5089)  loss_objectness: 0.0175 (0.0272)  loss_rpn_box_reg: 0.0077 (0.0118)  time: 12.1604  data: 0.0469\n",
      "Epoch: [1]  [ 70/245]  eta: 0:35:56  lr: 0.000100  loss: 0.7076 (0.7197)  loss_classifier: 0.0686 (0.0711)  loss_box_reg: 0.1067 (0.1041)  loss_mask: 0.4937 (0.5081)  loss_objectness: 0.0156 (0.0254)  loss_rpn_box_reg: 0.0061 (0.0110)  time: 12.0408  data: 0.0465\n",
      "Epoch: [1]  [ 80/245]  eta: 0:33:47  lr: 0.000100  loss: 0.7158 (0.7232)  loss_classifier: 0.0701 (0.0720)  loss_box_reg: 0.1047 (0.1045)  loss_mask: 0.5013 (0.5118)  loss_objectness: 0.0149 (0.0243)  loss_rpn_box_reg: 0.0058 (0.0105)  time: 12.0129  data: 0.0457\n",
      "Epoch: [1]  [ 90/245]  eta: 0:31:29  lr: 0.000100  loss: 0.7091 (0.7181)  loss_classifier: 0.0701 (0.0710)  loss_box_reg: 0.0999 (0.1028)  loss_mask: 0.4993 (0.5110)  loss_objectness: 0.0137 (0.0231)  loss_rpn_box_reg: 0.0071 (0.0102)  time: 11.7051  data: 0.0461\n",
      "Epoch: [1]  [100/245]  eta: 0:29:14  lr: 0.000100  loss: 0.6806 (0.7144)  loss_classifier: 0.0606 (0.0702)  loss_box_reg: 0.0976 (0.1024)  loss_mask: 0.4876 (0.5075)  loss_objectness: 0.0112 (0.0235)  loss_rpn_box_reg: 0.0075 (0.0108)  time: 11.3393  data: 0.0463\n",
      "Epoch: [1]  [110/245]  eta: 0:27:04  lr: 0.000100  loss: 0.6681 (0.7113)  loss_classifier: 0.0665 (0.0705)  loss_box_reg: 0.1084 (0.1028)  loss_mask: 0.4827 (0.5051)  loss_objectness: 0.0106 (0.0224)  loss_rpn_box_reg: 0.0078 (0.0105)  time: 11.3317  data: 0.0474\n",
      "Epoch: [1]  [120/245]  eta: 0:24:58  lr: 0.000100  loss: 0.6681 (0.7121)  loss_classifier: 0.0772 (0.0714)  loss_box_reg: 0.0905 (0.1030)  loss_mask: 0.4652 (0.5030)  loss_objectness: 0.0112 (0.0240)  loss_rpn_box_reg: 0.0083 (0.0107)  time: 11.4344  data: 0.0481\n",
      "Epoch: [1]  [130/245]  eta: 0:22:53  lr: 0.000100  loss: 0.6698 (0.7073)  loss_classifier: 0.0719 (0.0711)  loss_box_reg: 0.0894 (0.1018)  loss_mask: 0.4691 (0.5009)  loss_objectness: 0.0139 (0.0231)  loss_rpn_box_reg: 0.0065 (0.0104)  time: 11.4165  data: 0.0463\n",
      "Epoch: [1]  [140/245]  eta: 0:20:47  lr: 0.000100  loss: 0.6563 (0.7057)  loss_classifier: 0.0664 (0.0708)  loss_box_reg: 0.0931 (0.1013)  loss_mask: 0.4938 (0.5011)  loss_objectness: 0.0119 (0.0224)  loss_rpn_box_reg: 0.0061 (0.0102)  time: 11.2264  data: 0.0444\n",
      "Epoch: [1]  [150/245]  eta: 0:18:45  lr: 0.000100  loss: 0.6450 (0.7016)  loss_classifier: 0.0546 (0.0696)  loss_box_reg: 0.0931 (0.1002)  loss_mask: 0.4790 (0.4998)  loss_objectness: 0.0108 (0.0217)  loss_rpn_box_reg: 0.0075 (0.0103)  time: 11.2650  data: 0.0468\n",
      "Epoch: [1]  [160/245]  eta: 0:16:44  lr: 0.000100  loss: 0.6354 (0.6976)  loss_classifier: 0.0548 (0.0695)  loss_box_reg: 0.0880 (0.0994)  loss_mask: 0.4737 (0.4977)  loss_objectness: 0.0091 (0.0209)  loss_rpn_box_reg: 0.0053 (0.0100)  time: 11.3613  data: 0.0490\n",
      "Epoch: [1]  [170/245]  eta: 0:14:43  lr: 0.000100  loss: 0.6357 (0.6936)  loss_classifier: 0.0642 (0.0693)  loss_box_reg: 0.0889 (0.0989)  loss_mask: 0.4473 (0.4952)  loss_objectness: 0.0081 (0.0203)  loss_rpn_box_reg: 0.0053 (0.0099)  time: 11.2840  data: 0.0479\n",
      "Epoch: [1]  [180/245]  eta: 0:12:44  lr: 0.000100  loss: 0.6131 (0.6887)  loss_classifier: 0.0582 (0.0684)  loss_box_reg: 0.0793 (0.0979)  loss_mask: 0.4446 (0.4925)  loss_objectness: 0.0087 (0.0200)  loss_rpn_box_reg: 0.0061 (0.0099)  time: 11.2893  data: 0.0474\n",
      "Epoch: [1]  [190/245]  eta: 0:10:45  lr: 0.000100  loss: 0.5993 (0.6842)  loss_classifier: 0.0550 (0.0678)  loss_box_reg: 0.0841 (0.0979)  loss_mask: 0.4325 (0.4890)  loss_objectness: 0.0075 (0.0194)  loss_rpn_box_reg: 0.0072 (0.0101)  time: 11.3434  data: 0.0467\n",
      "Epoch: [1]  [200/245]  eta: 0:08:47  lr: 0.000100  loss: 0.6188 (0.6821)  loss_classifier: 0.0590 (0.0682)  loss_box_reg: 0.1019 (0.0980)  loss_mask: 0.4278 (0.4871)  loss_objectness: 0.0075 (0.0188)  loss_rpn_box_reg: 0.0074 (0.0100)  time: 11.4188  data: 0.0458\n",
      "Epoch: [1]  [210/245]  eta: 0:06:49  lr: 0.000100  loss: 0.6483 (0.6807)  loss_classifier: 0.0606 (0.0679)  loss_box_reg: 0.0926 (0.0978)  loss_mask: 0.4344 (0.4866)  loss_objectness: 0.0083 (0.0186)  loss_rpn_box_reg: 0.0057 (0.0098)  time: 11.4444  data: 0.0459\n",
      "Epoch: [1]  [220/245]  eta: 0:04:52  lr: 0.000100  loss: 0.6298 (0.6803)  loss_classifier: 0.0557 (0.0678)  loss_box_reg: 0.0876 (0.0975)  loss_mask: 0.4726 (0.4871)  loss_objectness: 0.0074 (0.0181)  loss_rpn_box_reg: 0.0057 (0.0098)  time: 11.3488  data: 0.0463\n",
      "Epoch: [1]  [230/245]  eta: 0:02:55  lr: 0.000100  loss: 0.6265 (0.6792)  loss_classifier: 0.0558 (0.0676)  loss_box_reg: 0.0876 (0.0973)  loss_mask: 0.4349 (0.4850)  loss_objectness: 0.0075 (0.0191)  loss_rpn_box_reg: 0.0074 (0.0103)  time: 11.2740  data: 0.0483\n",
      "Epoch: [1]  [240/245]  eta: 0:00:58  lr: 0.000100  loss: 0.6294 (0.6791)  loss_classifier: 0.0586 (0.0676)  loss_box_reg: 0.0815 (0.0969)  loss_mask: 0.4444 (0.4857)  loss_objectness: 0.0078 (0.0187)  loss_rpn_box_reg: 0.0073 (0.0101)  time: 11.2746  data: 0.0479\n",
      "Epoch: [1]  [244/245]  eta: 0:00:11  lr: 0.000100  loss: 0.6269 (0.6782)  loss_classifier: 0.0581 (0.0674)  loss_box_reg: 0.0886 (0.0971)  loss_mask: 0.4664 (0.4850)  loss_objectness: 0.0083 (0.0186)  loss_rpn_box_reg: 0.0068 (0.0101)  time: 11.2923  data: 0.0476\n",
      "Epoch: [1] Total time: 0:47:35 (11.6550 s / it)\n",
      "Epoch: [2]  [  0/245]  eta: 0:54:22  lr: 0.000100  loss: 0.6703 (0.6703)  loss_classifier: 0.0746 (0.0746)  loss_box_reg: 0.1165 (0.1165)  loss_mask: 0.4576 (0.4576)  loss_objectness: 0.0119 (0.0119)  loss_rpn_box_reg: 0.0097 (0.0097)  time: 13.3150  data: 0.0472\n",
      "Epoch: [2]  [ 10/245]  eta: 0:46:09  lr: 0.000100  loss: 0.5951 (0.6015)  loss_classifier: 0.0538 (0.0559)  loss_box_reg: 0.0830 (0.0889)  loss_mask: 0.4362 (0.4421)  loss_objectness: 0.0072 (0.0076)  loss_rpn_box_reg: 0.0072 (0.0070)  time: 11.7836  data: 0.0474\n",
      "Epoch: [2]  [ 20/245]  eta: 0:43:36  lr: 0.000100  loss: 0.5951 (0.6099)  loss_classifier: 0.0538 (0.0561)  loss_box_reg: 0.0820 (0.0890)  loss_mask: 0.4399 (0.4502)  loss_objectness: 0.0072 (0.0075)  loss_rpn_box_reg: 0.0063 (0.0072)  time: 11.5431  data: 0.0475\n",
      "Epoch: [2]  [ 30/245]  eta: 0:41:50  lr: 0.000100  loss: 0.5966 (0.6166)  loss_classifier: 0.0598 (0.0589)  loss_box_reg: 0.0920 (0.0896)  loss_mask: 0.4399 (0.4412)  loss_objectness: 0.0075 (0.0174)  loss_rpn_box_reg: 0.0064 (0.0095)  time: 11.6146  data: 0.0499\n",
      "Epoch: [2]  [ 40/245]  eta: 0:40:08  lr: 0.000100  loss: 0.5789 (0.6132)  loss_classifier: 0.0587 (0.0583)  loss_box_reg: 0.0896 (0.0881)  loss_mask: 0.4331 (0.4432)  loss_objectness: 0.0076 (0.0151)  loss_rpn_box_reg: 0.0057 (0.0085)  time: 11.8787  data: 0.0541\n",
      "Epoch: [2]  [ 50/245]  eta: 0:38:03  lr: 0.000100  loss: 0.5846 (0.6220)  loss_classifier: 0.0534 (0.0585)  loss_box_reg: 0.0828 (0.0864)  loss_mask: 0.4468 (0.4490)  loss_objectness: 0.0083 (0.0170)  loss_rpn_box_reg: 0.0049 (0.0111)  time: 11.7715  data: 0.0525\n",
      "Epoch: [2]  [ 60/245]  eta: 0:36:07  lr: 0.000100  loss: 0.6079 (0.6239)  loss_classifier: 0.0596 (0.0597)  loss_box_reg: 0.0906 (0.0883)  loss_mask: 0.4497 (0.4495)  loss_objectness: 0.0104 (0.0160)  loss_rpn_box_reg: 0.0050 (0.0103)  time: 11.6406  data: 0.0495\n",
      "Epoch: [2]  [ 70/245]  eta: 0:34:08  lr: 0.000100  loss: 0.6247 (0.6246)  loss_classifier: 0.0590 (0.0602)  loss_box_reg: 0.0950 (0.0897)  loss_mask: 0.4497 (0.4497)  loss_objectness: 0.0091 (0.0148)  loss_rpn_box_reg: 0.0062 (0.0101)  time: 11.6934  data: 0.0540\n",
      "Epoch: [2]  [ 80/245]  eta: 0:32:07  lr: 0.000100  loss: 0.6101 (0.6243)  loss_classifier: 0.0590 (0.0595)  loss_box_reg: 0.0937 (0.0906)  loss_mask: 0.4553 (0.4503)  loss_objectness: 0.0070 (0.0139)  loss_rpn_box_reg: 0.0075 (0.0100)  time: 11.5809  data: 0.0546\n",
      "Epoch: [2]  [ 90/245]  eta: 0:30:15  lr: 0.000100  loss: 0.6188 (0.6237)  loss_classifier: 0.0543 (0.0592)  loss_box_reg: 0.0937 (0.0903)  loss_mask: 0.4589 (0.4514)  loss_objectness: 0.0061 (0.0132)  loss_rpn_box_reg: 0.0067 (0.0097)  time: 11.7256  data: 0.0510\n",
      "Epoch: [2]  [100/245]  eta: 0:28:12  lr: 0.000100  loss: 0.5974 (0.6219)  loss_classifier: 0.0535 (0.0590)  loss_box_reg: 0.0814 (0.0891)  loss_mask: 0.4413 (0.4519)  loss_objectness: 0.0055 (0.0126)  loss_rpn_box_reg: 0.0066 (0.0094)  time: 11.6478  data: 0.0480\n",
      "Epoch: [2]  [110/245]  eta: 0:26:20  lr: 0.000100  loss: 0.6194 (0.6228)  loss_classifier: 0.0558 (0.0593)  loss_box_reg: 0.0810 (0.0890)  loss_mask: 0.4413 (0.4532)  loss_objectness: 0.0054 (0.0121)  loss_rpn_box_reg: 0.0064 (0.0092)  time: 11.7035  data: 0.0470\n",
      "Epoch: [2]  [120/245]  eta: 0:24:27  lr: 0.000100  loss: 0.6206 (0.6244)  loss_classifier: 0.0633 (0.0603)  loss_box_reg: 0.0862 (0.0888)  loss_mask: 0.4529 (0.4542)  loss_objectness: 0.0061 (0.0120)  loss_rpn_box_reg: 0.0059 (0.0090)  time: 12.0618  data: 0.0456\n",
      "Epoch: [2]  [130/245]  eta: 0:22:32  lr: 0.000100  loss: 0.5864 (0.6223)  loss_classifier: 0.0641 (0.0610)  loss_box_reg: 0.0877 (0.0892)  loss_mask: 0.4230 (0.4511)  loss_objectness: 0.0088 (0.0121)  loss_rpn_box_reg: 0.0076 (0.0090)  time: 12.0315  data: 0.0444\n",
      "Epoch: [2]  [140/245]  eta: 0:20:35  lr: 0.000100  loss: 0.6060 (0.6240)  loss_classifier: 0.0641 (0.0611)  loss_box_reg: 0.0847 (0.0894)  loss_mask: 0.4230 (0.4500)  loss_objectness: 0.0059 (0.0134)  loss_rpn_box_reg: 0.0076 (0.0101)  time: 11.9082  data: 0.0453\n",
      "Epoch: [2]  [150/245]  eta: 0:18:37  lr: 0.000100  loss: 0.6060 (0.6231)  loss_classifier: 0.0569 (0.0609)  loss_box_reg: 0.0847 (0.0894)  loss_mask: 0.4324 (0.4498)  loss_objectness: 0.0071 (0.0132)  loss_rpn_box_reg: 0.0064 (0.0099)  time: 11.8164  data: 0.0432\n",
      "Epoch: [2]  [160/245]  eta: 0:16:39  lr: 0.000100  loss: 0.6103 (0.6246)  loss_classifier: 0.0615 (0.0612)  loss_box_reg: 0.0960 (0.0902)  loss_mask: 0.4515 (0.4503)  loss_objectness: 0.0098 (0.0132)  loss_rpn_box_reg: 0.0056 (0.0098)  time: 11.7453  data: 0.0422\n",
      "Epoch: [2]  [170/245]  eta: 0:14:41  lr: 0.000100  loss: 0.6442 (0.6247)  loss_classifier: 0.0619 (0.0612)  loss_box_reg: 0.0993 (0.0904)  loss_mask: 0.4488 (0.4505)  loss_objectness: 0.0097 (0.0129)  loss_rpn_box_reg: 0.0075 (0.0097)  time: 11.6377  data: 0.0452\n",
      "Epoch: [2]  [180/245]  eta: 0:12:44  lr: 0.000100  loss: 0.6153 (0.6236)  loss_classifier: 0.0581 (0.0610)  loss_box_reg: 0.0856 (0.0901)  loss_mask: 0.4413 (0.4496)  loss_objectness: 0.0062 (0.0129)  loss_rpn_box_reg: 0.0072 (0.0100)  time: 11.7591  data: 0.0461\n",
      "Epoch: [2]  [190/245]  eta: 0:10:48  lr: 0.000100  loss: 0.5790 (0.6212)  loss_classifier: 0.0558 (0.0607)  loss_box_reg: 0.0890 (0.0900)  loss_mask: 0.4243 (0.4482)  loss_objectness: 0.0053 (0.0125)  loss_rpn_box_reg: 0.0056 (0.0098)  time: 12.0542  data: 0.0463\n",
      "Epoch: [2]  [200/245]  eta: 0:08:50  lr: 0.000100  loss: 0.5790 (0.6219)  loss_classifier: 0.0596 (0.0612)  loss_box_reg: 0.0921 (0.0906)  loss_mask: 0.4243 (0.4482)  loss_objectness: 0.0053 (0.0122)  loss_rpn_box_reg: 0.0072 (0.0097)  time: 12.1424  data: 0.0486\n",
      "Epoch: [2]  [210/245]  eta: 0:06:55  lr: 0.000100  loss: 0.6100 (0.6218)  loss_classifier: 0.0583 (0.0609)  loss_box_reg: 0.0975 (0.0910)  loss_mask: 0.4411 (0.4485)  loss_objectness: 0.0063 (0.0119)  loss_rpn_box_reg: 0.0066 (0.0095)  time: 12.6357  data: 0.0459\n",
      "Epoch: [2]  [220/245]  eta: 0:04:57  lr: 0.000100  loss: 0.5914 (0.6208)  loss_classifier: 0.0564 (0.0608)  loss_box_reg: 0.0975 (0.0915)  loss_mask: 0.4341 (0.4473)  loss_objectness: 0.0046 (0.0116)  loss_rpn_box_reg: 0.0052 (0.0096)  time: 13.0150  data: 0.0436\n",
      "Epoch: [2]  [230/245]  eta: 0:02:58  lr: 0.000100  loss: 0.5914 (0.6200)  loss_classifier: 0.0564 (0.0606)  loss_box_reg: 0.0863 (0.0913)  loss_mask: 0.4295 (0.4469)  loss_objectness: 0.0049 (0.0117)  loss_rpn_box_reg: 0.0062 (0.0096)  time: 12.5789  data: 0.0409\n",
      "Epoch: [2]  [240/245]  eta: 0:00:59  lr: 0.000100  loss: 0.5703 (0.6187)  loss_classifier: 0.0536 (0.0607)  loss_box_reg: 0.0840 (0.0911)  loss_mask: 0.4261 (0.4459)  loss_objectness: 0.0078 (0.0115)  loss_rpn_box_reg: 0.0069 (0.0095)  time: 12.6804  data: 0.0403\n",
      "Epoch: [2]  [244/245]  eta: 0:00:12  lr: 0.000100  loss: 0.5650 (0.6182)  loss_classifier: 0.0536 (0.0606)  loss_box_reg: 0.0795 (0.0908)  loss_mask: 0.4254 (0.4460)  loss_objectness: 0.0078 (0.0115)  loss_rpn_box_reg: 0.0052 (0.0094)  time: 13.0049  data: 0.0410\n",
      "Epoch: [2] Total time: 0:49:00 (12.0014 s / it)\n"
     ]
    }
   ],
   "source": [
    "# [START Training]\n",
    "torch.cuda.empty_cache() # empty GPU cache\n",
    "\n",
    "# load data\n",
    "dataloader_dict = get_dataloader_dict(\n",
    "    train_df=df[(df['train_group']=='training')],\n",
    "    val_df=df[(df['train_group']=='validation')],\n",
    "    image_dir=config['image_dir'],\n",
    "    batch_size=config['batch_size']\n",
    ")\n",
    "\n",
    "# initialise Tensorboard writer\n",
    "tb_log_dir = config['log_dir'] + 'logs_train/'\n",
    "writer = SummaryWriter(log_dir=tb_log_dir)\n",
    "\n",
    "# get the model\n",
    "zoobot = get_model(\n",
    "    ckpt=config['pretrained_ckpt'],\n",
    "    num_classes=config['num_classes'],\n",
    "    trainable_layers=config['trainable_layers'],\n",
    "    image_mean=config['image_mean'],\n",
    "    image_std=config['image_std'],\n",
    ")  \n",
    "\n",
    "# move model to the right device and using all available GPUs\n",
    "zoobot = nn.DataParallel(zoobot)\n",
    "zoobot.to(TORCH_DEVICE)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in zoobot.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = torch.optim.Adam(params, lr=0.0001, weight_decay=0.00005)\n",
    "\n",
    "# and a learning rate scheduler, comment for Adam\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "#     optimizer,\n",
    "#     step_size=3,\n",
    "#     gamma=0.1\n",
    "# )\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    engine.train_one_epoch(\n",
    "        zoobot, \n",
    "        optimizer, \n",
    "        dataloader_dict['train'], \n",
    "        device=TORCH_DEVICE, \n",
    "        epoch=epoch, \n",
    "        print_freq=10,\n",
    "        scaler=None,\n",
    "        tb_writer=writer\n",
    "        # tb_writer=None\n",
    "    )\n",
    "    \n",
    "    # update the learning rate\n",
    "    # lr_scheduler.step()\n",
    "\n",
    "    engine.evaluate_loss(\n",
    "        zoobot, \n",
    "        dataloader_dict['val'], \n",
    "        device=TORCH_DEVICE, \n",
    "        epoch=epoch, \n",
    "        tb_writer=writer\n",
    "        # tb_writer=None\n",
    "    )\n",
    "\n",
    "    # evaluate on the test dataset\n",
    "    engine.evaluate(\n",
    "        zoobot, \n",
    "        dataloader_dict['val'], \n",
    "        device=TORCH_DEVICE,\n",
    "        epoch=epoch, \n",
    "        tb_writer=writer\n",
    "        # tb_writer=None\n",
    "    )\n",
    "\n",
    "    # save model for each epoch\n",
    "    model_save_path = config['log_dir'] + 'MaskRCNN_Zoobot_epoch_{}.pth'.format(epoch)\n",
    "    torch.save(zoobot.state_dict(), model_save_path)\n",
    "\n",
    "# [END Training]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
